{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in blocks and assign a unique index\n",
    "gdfBlocks = gpd.read_file('../data/DURHAM/DURHAM_blocks.shp')\n",
    "gdfBlocks[\"OrgID\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select blocks that are majority black\n",
    "gdfMajBlack = gdfBlocks.query('PctBlack >= 50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Of those, select blocks that have at least 50 BHH, these we'll keep (1)\n",
    "gdf_Org1 = gdfMajBlack.query('BlackHH > 50').reset_index()\n",
    "gdf_Org1.drop(['index', 'STATEFP10', 'COUNTYFP10', \n",
    "               'TRACTCE10', 'BLOCKCE', 'BLOCKID10',\n",
    "               'GEOID10','PARTFLG'],axis=1,inplace=True)\n",
    "gdf_Org1['OrgID'] = gdf_Org1.index + 1\n",
    "gdf_Org1['OrgType'] = 'OriginalBlock'\n",
    "gdf_Org1.to_file(keep1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Of those, select blocks that have fewer than 50 BHH; these we'll cluster\n",
    "gdfMajBlack_LT50 = gdfMajBlack.query('BlackHH < 50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cluster\n",
    "gdfClusters = gpd.GeoDataFrame(geometry = list(gdfMajBlack_LT50.unary_union))\n",
    "gdfClusters['ClusterID'] = gdfClusters.index\n",
    "gdfClusters.crs = gdfMajBlack_LT50.crs\n",
    "#gdfClusters.to_file('../data/DURHAM/clusters.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spatially join the cluster ID to the original blocks\n",
    "gdfMajBlack_LT50_2 = gpd.sjoin(gdfMajBlack_LT50,gdfClusters,\n",
    "                               how='left',op='within').drop(\"index_right\",axis=1)\n",
    "#gdfMajBlack_LT50_2.to_file('../data/DURHAM/MajBlack1.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the total BHH for the dissolved blocks and add as block attribute\n",
    "gdfClusters_2 = gdfMajBlack_LT50_2.dissolve(by='ClusterID', aggfunc='sum')\n",
    "gdfClusters_2['PctBlack'] = gdfClusters_2['P003003'] / gdfClusters_2['P003001'] * 100\n",
    "gdfClusters_2['PctBlack18'] = gdfClusters_2['P010004'] / gdfClusters_2['P010001'] * 100\n",
    "\n",
    "#Remove block clusters with fewer than 50 BHH; these are impractical\n",
    "gdfClusters_2 = gdfClusters_2.query('BlackHH >= 50')\n",
    "#gdfClusters_2.to_file('../data/DURHAM/clusters2.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select clusters with fewer than 100 BHH, these we'll keep as org units(2)\n",
    "gdf_Org2 = gdfClusters_2.query('BlackHH <= 100').reset_index()\n",
    "gdf_Org2['OrgID'] = gdf_Org1['OrgID'].max() + gdf_Org2.index + 1\n",
    "gdf_Org2['OrgType'] = 'Full block cluster'\n",
    "gdf_Org2.to_file('../data/DURHAM/keep2.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get a list of Cluster IDs for block clusters with more than 100 BHH;\n",
    "# we'll cluster individual blocks with these IDs until BHH >= 100\n",
    "clusterIDs = gdfClusters_2.query('BlackHH > 100').index.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdfClusters_2.query('BlackHH > 100').to_file('../data/DURHAM/cluster.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterID = 5\n",
    "gdfBlksAll = gdfMajBlack_LT50_2.query('ClusterID == {}'.format(clusterID)).reset_index()\n",
    "\n",
    "gdfBlksAll['X'] = gdfBlksAll.geometry.centroid.x\n",
    "gdfBlksAll['claimed'] = 0\n",
    "geomDict = {}\n",
    "gdfList = []\n",
    "unclaimedCount = gdfBlksAll.query('claimed == 0')['X'].count()\n",
    "#print(unclaimedCount)\n",
    "stopIt2 = 0 \n",
    "while unclaimedCount > 0:\n",
    "    gdfBlks = gdfBlksAll[gdfBlksAll.claimed == 0].reset_index()\n",
    "\n",
    "    gdfNbrs = gdfBlks[gdfBlks.X == gdfBlks.X.min()]#; print(gdfNbrs.BLOCKID10.unique())\n",
    "    BHH = gdfNbrs.BlackHH.sum()\n",
    "    geom = gdfNbrs.geometry.unary_union\n",
    "    #gdfNbrs.plot();\n",
    "    stopIt = 0\n",
    "    while BHH < 100:\n",
    "        gdfNbrs = gdfBlksAll[(gdfBlksAll.intersects(geom)) &\n",
    "                             (gdfBlksAll.claimed == 0)\n",
    "                            ]#; print(gdfNbrs.BLOCKID10.unique())\n",
    "        BHH = gdfNbrs.BlackHH.sum()\n",
    "        geom = gdfNbrs.geometry.unary_union\n",
    "        #gdfNbrs.plot();\n",
    "        stopIt += 1\n",
    "        if stopIt > 100: \n",
    "            print(\"BHH never reached 100\")\n",
    "            break\n",
    "\n",
    "    gdfBlksAll.loc[gdfBlksAll.geometry.intersects(geom),'claimed'] = 1\n",
    "    unclaimedCount = gdfBlksAll.query('claimed == 0')['X'].count()\n",
    "    #print(stopIt2,unclaimedCount)\n",
    "    stopIt2 += 1\n",
    "    if stopIt2 > 100: break\n",
    "    geomDict[stopIt2] = geom\n",
    "\n",
    "    gdfSelect = (gdfBlksAll[(gdfBlksAll.centroid.within(geom))]\n",
    "                 .reset_index()\n",
    "                 .dissolve(by='ClusterID', aggfunc='sum')\n",
    "                 .drop(['level_0','index','X'],axis=1)\n",
    "                )\n",
    "    #gdfSelect['OrgID'] = stopIt2\n",
    "    gdfList.append(gdfSelect)\n",
    "    \n",
    "gdf5 = pd.concat(gdfList)\n",
    "gdf5.to_file(\"../data/DURHAM/foo5.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdfSelect = (gdfBlksAll[(gdfBlksAll.geometry.intersects(geom)) & (gdfBlksAll.claimed == 0)]\n",
    "             .reset_index()\n",
    "             .dissolve(by='ClusterID', aggfunc='sum')\n",
    "             .drop(['level_0','index','X'],axis=1)\n",
    "            )\n",
    "    #gdfSelect.plot()\n",
    "\n",
    "gdfBlksAll.loc[gdfBlksAll.geometry.intersects(geom),'claimed'] = 1\n",
    "print(gdfBlksAll.query('claimed == 0')['X'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate through each clusterID\n",
    "gdfs = []\n",
    "for clusterID in clusterIDs:\n",
    "    #Get all the blocks in the selected cluster\n",
    "    gdfBlksAll = gdfMajBlack_LT50_2.query('ClusterID == {}'.format(clusterID)).reset_index()\n",
    "\n",
    "    #Assign the X coordinate, used to select the first feature in a sub-cluster\n",
    "    gdfBlksAll['X'] = gdfBlksAll.geometry.centroid.x\n",
    "    #Set all blocks to \"unclaimed\"\n",
    "    gdfBlksAll['claimed'] = 0\n",
    "    #Determine how many blocks are unclaimed\n",
    "    unclaimedCount = gdfBlksAll.query('claimed == 0')['X'].count()\n",
    "    #Initialize the loop catch variable\n",
    "    stopLoop = 0 \n",
    "    #Run until all blocks have been \"claimed\"\n",
    "    while unclaimedCount > 0:\n",
    "        \n",
    "        #Extract all unclaimed blocks\n",
    "        gdfBlks = gdfBlksAll[gdfBlksAll.claimed == 0].reset_index()\n",
    "\n",
    "        #Get the initial block (the western most one); get its BHH and geometry\n",
    "        gdfBlock = gdfBlks[gdfBlks.X == gdfBlks.X.min()]\n",
    "        BHH = gdfBlock.BlackHH.sum()\n",
    "        geom = gdfBlock.geometry.unary_union\n",
    "        \n",
    "        #Expand the geometry until 100 BHH are found\n",
    "        stopLoop2 = 0 #Loop break check\n",
    "        while BHH < 100:\n",
    "            #Select unclaimed blocks that within the area\n",
    "            gdfNbrs = gdfBlksAll[(gdfBlksAll.touches(geom))]\n",
    "            gdfBoth = pd.concat((gdfBlock,gdfNbrs),axis='rows',sort=False)\n",
    "            gdfBlock = gdfBoth.copy(deep=True)\n",
    "            #Tally the BHHs in the area and update the area shape\n",
    "            BHH = gdfBoth.BlackHH.sum()\n",
    "            geom = gdfBoth.geometry.unary_union\n",
    "            #Catch if run 100 times without getting to 100 BHH\n",
    "            stopLoop2 += 1\n",
    "            if stopLoop2 > 100: \n",
    "                print(\"BHH never reached 100\")\n",
    "                break\n",
    "                \n",
    "        #Extract features intersecting the geometry to a new dataframe\n",
    "        gdfSelect = (gdfBlksAll[(gdfBlksAll.centroid.within(geom)) & \n",
    "                                (gdfBlksAll.claimed == 0) \n",
    "                               ]\n",
    "                 .reset_index()\n",
    "                 .dissolve(by='ClusterID', aggfunc='sum')\n",
    "                 .drop(['level_0','index','X'],axis=1)\n",
    "                )\n",
    "        \n",
    "        #Set all features intersecting the shape as \"claimed\"\n",
    "        gdfBlksAll.loc[gdfBlksAll.geometry.centroid.within(geom),'claimed'] = 1\n",
    "        unclaimedCount = gdfBlksAll.query('claimed == 0')['X'].count()\n",
    "\n",
    "        #Add the dataframe to the list of datarames\n",
    "        gdfs.append(gdfSelect[gdfSelect['BlackHH'] >= 50])    \n",
    "        \n",
    "        #Stop the loop if run for over 100 iterations\n",
    "        stopLoop += 1\n",
    "        if stopLoop > 100: break\n",
    "            \n",
    "pd.concat(gdfs).to_file('../data/Durham/Foo5x.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['geometry', 'HOUSING10', 'POP10', 'P003001', 'P003003', 'P010001',\n",
       "       'P010004', 'PctBlack', 'PctBlack18', 'BlackHH', 'OrgID', 'claimed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_Orgx = pd.concat(gdfs)\n",
    "gdf_Orgx.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_Orgx = pd.concat(gdfs)\n",
    "gdf_Org3 = gdf_Orgx.query('claimed > 0').reset_index()\n",
    "gdf_Org3.BlackHH.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_Org3['PctBlack'] = gdf_Org3['P003003'] / gdf_Org3['P003001'] * 100\n",
    "gdf_Org3['PctBlack18'] = gdf_Org3['P010004'] / gdf_Org3['P010001'] * 100\n",
    "gdf_Org3.to_file('../data/Durham/Keep3.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign a unique ID to each org unit\n",
    "for i,df in enumerate(gdfs):\n",
    "    df['OrgIDx'] = i\n",
    "#Combine all together    \n",
    "gdf_Org3 = pd.concat(gdfs).reset_index()\n",
    "#gdf_Org3 = gdfsClaimed.dissolve(by='OrgIDx',aggfunc='sum')\n",
    "\n",
    "#Combine each cluster into a single dataframe and write to a file\n",
    "#gdf_Org3 = pd.concat(gdfs).reset_index()\n",
    "gdf_Org3['OrgID'] = gdf_Org2['OrgID'].max() + gdf_Org3.index + 1\n",
    "gdf_Org3['OrgType'] = 'Partial block cluster'\n",
    "gdf_Org3.to_file('../data/Durham/Keep3.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge all three keepers\n",
    "gdfAllOrgs = pd.concat((gdf_Org1, gdf_Org2, gdf_Org3),axis=0,sort=True)\n",
    "gdfAllOrgs.to_file('../data/DURHAM/Orgs.shp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
