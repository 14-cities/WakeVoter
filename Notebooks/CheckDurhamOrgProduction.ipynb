{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "majBlackFN = '../data/DURHAM/MajBlack.shp'\n",
    "keep1 = '../data/DURHAM/keep1.shp'\n",
    "clusters  = '../data/DURHAM/clusters.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in blocks and assign a unique index\n",
    "gdfBlocks = gpd.read_file('../data/DURHAM/DURHAM_blocks.shp')\n",
    "gdfBlocks[\"OrgID\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select blocks that are majority black\n",
    "gdfMajBlack = gdfBlocks.query('PctBlack >= 50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Of those, select blocks that have at least 50 BHH, these we'll keep (1)\n",
    "gdf_Org1 = gdfMajBlack.query('BlackHH > 50').reset_index()\n",
    "gdf_Org1.drop(['index', 'STATEFP10', 'COUNTYFP10', \n",
    "               'TRACTCE10', 'BLOCKCE', 'BLOCKID10',\n",
    "               'GEOID10','PARTFLG'],axis=1,inplace=True)\n",
    "gdf_Org1['OrgID'] = gdf_Org1.index + 1\n",
    "gdf_Org1['OrgType'] = 'OriginalBlock'\n",
    "gdf_Org1.to_file(keep1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Of those, select blocks that have fewer than 50 BHH; these we'll cluster\n",
    "gdfMajBlack_LT50 = gdfMajBlack.query('BlackHH < 50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cluster\n",
    "gdfClusters = gpd.GeoDataFrame(geometry = list(gdfMajBlack_LT50.unary_union))\n",
    "gdfClusters['ClusterID'] = gdfClusters.index\n",
    "gdfClusters.crs = gdfMajBlack_LT50.crs\n",
    "#gdfClusters.to_file('../data/DURHAM/clusters.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spatially join the cluster ID to the original blocks\n",
    "gdfMajBlack_LT50_2 = gpd.sjoin(gdfMajBlack_LT50,gdfClusters,\n",
    "                               how='left',op='within').drop(\"index_right\",axis=1)\n",
    "#gdfMajBlack_LT50_2.to_file('../data/DURHAM/MajBlack1.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the total BHH for the dissolved blocks and add as block attribute\n",
    "gdfClusters_2 = gdfMajBlack_LT50_2.dissolve(by='ClusterID', aggfunc='sum')\n",
    "gdfClusters_2['PctBlack'] = gdfClusters_2['P003003'] / gdfClusters_2['P003001'] * 100\n",
    "gdfClusters_2['PctBlack18'] = gdfClusters_2['P010004'] / gdfClusters_2['P010001'] * 100\n",
    "\n",
    "#Remove block clusters with fewer than 50 BHH; these are impractical\n",
    "gdfClusters_2 = gdfClusters_2.query('BlackHH >= 50')\n",
    "#gdfClusters_2.to_file('../data/DURHAM/clusters2.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select clusters with fewer than 100 BHH, these we'll keep as org units(2)\n",
    "gdf_Org2 = gdfClusters_2.query('BlackHH <= 100').reset_index()\n",
    "gdf_Org2['OrgID'] = gdf_Org1['OrgID'].max() + gdf_Org2.index + 1\n",
    "gdf_Org2['OrgType'] = 'Full block cluster'\n",
    "gdf_Org2.to_file('../data/DURHAM/keep2.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get a list of Cluster IDs for block clusters with more than 100 BHH;\n",
    "# we'll cluster individual blocks with these IDs until BHH >= 100\n",
    "clusterIDs = gdfClusters_2.query('BlackHH > 100').index.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate through each clusterID\n",
    "gdfs = []\n",
    "for clusterID in clusterIDs:\n",
    "    #Get the blocks in the cluster\n",
    "    gdfBlks = gdfMajBlack_LT50_2.query('ClusterID == {}'.format(clusterID)).reset_index()\n",
    "    #Get the first block in the block cluster\n",
    "    gdfBlks['X'] = gdfBlks.geometry.centroid.x\n",
    "    gdfNbrs = gdfBlks[gdfBlks['X'] == gdfBlks['X'].min()]\n",
    "    #Get the number of BHH and the geometry\n",
    "    BHH = gdfNbrs.BlackHH.sum()\n",
    "    geom = gdfNbrs.geometry.unary_union\n",
    "    \n",
    "    #Iterate while BHH <= 100\n",
    "    iter_count = 0\n",
    "    while BHH < 100 and iter_count < 100:\n",
    "        #Get the blocks that touch the current geometry\n",
    "        gdfNbrs = gdfBlks[gdfBlks.geometry.intersects(geom)]\n",
    "        #Compute the new aggregate BHH and Geometry\n",
    "        BHH = gdfNbrs.BlackHH.sum()\n",
    "        geom = gdfNbrs.geometry.unary_union\n",
    "        #Increae the iter_count to catch infinite loops\n",
    "        iter_count += 1\n",
    "        \n",
    "    #After 100 BHH are reached: select blocks intersecting the geom and assign an org unit ID\n",
    "    gdfSelect = (gdfBlks[gdfBlks.geometry.intersects(geom)]\n",
    "                 .reset_index()\n",
    "                 .dissolve(by='ClusterID', aggfunc='sum')\n",
    "                 .drop(['level_0','index','X'],axis=1)\n",
    "                )\n",
    "    \n",
    "    gdfs.append(gdfSelect)\n",
    "    \n",
    "\n",
    "#Combine each cluster into a single dataframe and write to a file\n",
    "gdf_Org3 = pd.concat(gdfs).reset_index()\n",
    "gdf_Org3['OrgID'] = gdf_Org2['OrgID'].max() + gdf_Org3.index + 1\n",
    "gdf_Org3['OrgType'] = 'Partial block cluster'\n",
    "gdf_Org3.to_file('../data/Durham/Keep3.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0:1 0 \n",
      " 1:6 3 2 0 \n",
      " 2:4 0 \n",
      " 4:42 37 30 23 22 20 14 6 2 0 \n",
      " 5:145 129 115 107 99 97 90 89 88 77 70 62 57 51 45 43 32 24 18 17 15 6 2 0 \n",
      " 6:84 72 62 54 45 44 34 33 26 25 16 11 8 7 0 \n",
      " 7:14 9 0 \n",
      " 49:1 0 \n",
      " 60:0 \n",
      " 72:8 1 0 \n",
      " 73:0 \n",
      " 76:2 0 \n",
      " 92:0 \n",
      " 94:9 8 7 6 5 2 0 \n",
      " 95:31 28 26 21 16 12 7 1 0 \n",
      " 96:0 \n",
      " 99:14 8 2 0 \n",
      " 120:2 0 \n",
      " 149:0 \n",
      " 181:4 0 \n",
      " 186:2 0 \n",
      " 202:0 \n",
      " 204:8 1 0 \n",
      " 206:8 1 0 \n",
      " 214:0 \n",
      " 222:39 37 34 28 15 13 10 4 0 \n",
      " 236:0 "
     ]
    }
   ],
   "source": [
    "#Iterate through each clusterID\n",
    "gdfs = []\n",
    "for clusterID in clusterIDs:\n",
    "    print('\\n',clusterID,end=\":\")\n",
    "    #Get the blocks in the cluster\n",
    "    gdfBlksAll = gdfMajBlack_LT50_2.query('ClusterID == {}'.format(clusterID)).reset_index()\n",
    "    #Add the X coordinte to start from side of cluster\n",
    "    gdfBlksAll['X'] = gdfBlksAll.geometry.centroid.x\n",
    "    #Set value indicating no blocks have been examined\n",
    "    gdfBlksAll['claimed'] = 0\n",
    "    \n",
    "    #Iterate until all block in the cluster have been examined\n",
    "    orgIDx = 1     #Id for the output sub-cluster\n",
    "    searchIter = 0 #Counter to avoid infinite loops\n",
    "    #Compute the number of unclaimed blocks\n",
    "    remainingBlocks = gdfBlksAll.query('claimed == 0')['X'].count()\n",
    "    \n",
    "    #Iterate until all blocks have been claimed (or iteration count > 100)\n",
    "    while remainingBlocks and searchIter < 100:\n",
    "        searchIter += 1\n",
    "        #Subset the unclaimed blocks in the cluster\n",
    "        gdfBlks = gdfBlksAll[gdfBlksAll.claimed == 0]\n",
    "        \n",
    "        #Get the eastern most block in the unclaimed block cluster, its BHH & geometry\n",
    "        gdfNbrs = gdfBlks[gdfBlks.X == gdfBlks.X.min()].reset_index()\n",
    "        BHH = gdfNbrs.BlackHH.sum()\n",
    "        geom = gdfNbrs.geometry.unary_union\n",
    "        \n",
    "        #Set that block as claimed inthe master block set\n",
    "        gdfBlksAll.loc[gdfBlksAll.geometry.intersects(geom),'claimed'] = 1\n",
    "\n",
    "        #Iterate while BHH <= 100\n",
    "        iter_count = 0\n",
    "        while BHH < 100 and iter_count < 100:\n",
    "            #Get the blocks that touch the current geometry\n",
    "            gdfNbrs = gdfBlks[gdfBlks.geometry.intersects(geom)]\n",
    "            #Compute the new aggregate BHH and Geometry\n",
    "            BHH = gdfNbrs.BlackHH.sum()\n",
    "            geom = gdfNbrs.geometry.unary_union\n",
    "            #Increae the iter_count to catch infinite loops\n",
    "            iter_count += 1\n",
    "\n",
    "        #After 100 BHH are reached: select blocks intersecting the geom and assign an org unit ID\n",
    "        gdfSelect = (gdfBlks[gdfBlksAll.geometry.intersects(geom)]\n",
    "                     .reset_index()\n",
    "                     .dissolve(by='ClusterID', aggfunc='sum')\n",
    "                     .drop(['level_0','index','X'],axis=1)\n",
    "                    )\n",
    "        \n",
    "        #Set those blocks as claimed\n",
    "        gdfBlksAll.loc[gdfBlksAll.geometry.intersects(geom),'claimed'] = 1\n",
    "        \n",
    "        #Compute the number of remaining blocks in the cluster\n",
    "        remainingBlocks = gdfBlksAll.query('claimed == 0')['X'].count()\n",
    "        \n",
    "        print(remainingBlocks,end=' ')\n",
    "        #Add tot h\n",
    "        gdfs.append(gdfSelect)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>HOUSING10</th>\n",
       "      <th>POP10</th>\n",
       "      <th>P003001</th>\n",
       "      <th>P003003</th>\n",
       "      <th>P010001</th>\n",
       "      <th>P010004</th>\n",
       "      <th>PctBlack</th>\n",
       "      <th>PctBlack18</th>\n",
       "      <th>BlackHH</th>\n",
       "      <th>OrgID</th>\n",
       "      <th>claimed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ClusterID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>POLYGON ((-78.846805 35.984318, -78.846757 35....</td>\n",
       "      <td>138</td>\n",
       "      <td>370</td>\n",
       "      <td>370</td>\n",
       "      <td>322</td>\n",
       "      <td>276</td>\n",
       "      <td>240</td>\n",
       "      <td>347.111742</td>\n",
       "      <td>345.312507</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    geometry  HOUSING10  \\\n",
       "ClusterID                                                                 \n",
       "236        POLYGON ((-78.846805 35.984318, -78.846757 35....        138   \n",
       "\n",
       "           POP10  P003001  P003003  P010001  P010004    PctBlack  PctBlack18  \\\n",
       "ClusterID                                                                      \n",
       "236          370      370      322      276      240  347.111742  345.312507   \n",
       "\n",
       "           BlackHH  OrgID  claimed  \n",
       "ClusterID                           \n",
       "236            118      0        0  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdfs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign a unique ID to each org unit\n",
    "for i,df in enumerate(gdfs):\n",
    "    df['OrgIDx'] = i\n",
    "#Combine all together    \n",
    "gdf_Org3 = pd.concat(gdfs).reset_index()\n",
    "#gdf_Org3 = gdfsClaimed.dissolve(by='OrgIDx',aggfunc='sum')\n",
    "\n",
    "#Combine each cluster into a single dataframe and write to a file\n",
    "#gdf_Org3 = pd.concat(gdfs).reset_index()\n",
    "gdf_Org3['OrgID'] = gdf_Org2['OrgID'].max() + gdf_Org3.index + 1\n",
    "gdf_Org3['OrgType'] = 'Partial block cluster'\n",
    "gdf_Org3.to_file('../data/Durham/Keep3.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge all three keepers\n",
    "gdfAllOrgs = pd.concat((gdf_Org1, gdf_Org2, gdf_Org3),axis=0,sort=True)\n",
    "gdfAllOrgs.to_file('../data/DURHAM/Orgs.shp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
